{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-mirantes/MCP/blob/main/notebooks/search/00-quick-start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87773ce7",
      "metadata": {
        "id": "87773ce7"
      },
      "source": [
        "# Semantic search quick start\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/00-quick-start.ipynb)\n",
        "\n",
        "This interactive notebook will introduce you to some basic operations with Elasticsearch, using the official [Elasticsearch Python client](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html).\n",
        "You'll perform semantic search using [Sentence Transformers](https://www.sbert.net) for text embedding. Learn how to integrate traditional text-based search with semantic search, for a hybrid search system."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a32202e2",
      "metadata": {
        "id": "a32202e2"
      },
      "source": [
        "## Create Elastic Cloud deployment\n",
        "\n",
        "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?onboarding_token=vectorsearch&utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial.\n",
        "\n",
        "Once logged in to your Elastic Cloud account, go to the [Create deployment](https://cloud.elastic.co/deployments/create) page and select **Create deployment**. Leave all settings with their default values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a6a607",
      "metadata": {
        "id": "52a6a607"
      },
      "source": [
        "## Install packages and import modules\n",
        "\n",
        "To get started, we'll need to connect to our Elastic deployment using the Python client.\n",
        "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
        "\n",
        "First we need to install the `elasticsearch` Python client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc5fa6f",
      "metadata": {
        "id": "ffc5fa6f"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \"elasticsearch<9\" #sentence-transformers==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28AH8LhI-0UD",
      "metadata": {
        "id": "28AH8LhI-0UD"
      },
      "source": [
        "# Setup the Embedding Model\n",
        "\n",
        "For this example, we're using `all-MiniLM-L6-v2`, part of the `sentence_transformers` library. You can read more about this model on [Huggingface](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WHC3hHGW-wbI",
      "metadata": {
        "id": "WHC3hHGW-wbI"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0241694c",
      "metadata": {
        "id": "0241694c"
      },
      "source": [
        "## Initialize the Elasticsearch client\n",
        "\n",
        "Now we can instantiate the [Elasticsearch python client](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html), providing the cloud id and password in your deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38e0397",
      "metadata": {
        "id": "f38e0397"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "from getpass import getpass\n",
        "\n",
        "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
        "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
        "\n",
        "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
        "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    # For local development\n",
        "    # hosts=[\"http://localhost:9200\"]\n",
        "    cloud_id=ELASTIC_CLOUD_ID,\n",
        "    api_key=ELASTIC_API_KEY,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcd165fa",
      "metadata": {
        "id": "fcd165fa"
      },
      "source": [
        "If you're running Elasticsearch locally or self-managed, you can pass in the Elasticsearch host instead. [Read more](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#_verifying_https_with_certificate_fingerprints_python_3_10_or_later) on how to connect to Elasticsearch locally."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb6ad7e9-0636-4cf3-a803-bf160fe16b33",
      "metadata": {
        "id": "cb6ad7e9-0636-4cf3-a803-bf160fe16b33"
      },
      "source": [
        "### Enable Telemetry\n",
        "\n",
        "Knowing that you are using this notebook helps us decide where to invest our efforts to improve our products. We would like to ask you that you run the following code to let us gather anonymous usage statistics. See [telemetry.py](https://github.com/elastic/elasticsearch-labs/blob/main/telemetry/telemetry.py) for details. Thank you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b04f442-729d-406d-b826-654483498df6",
      "metadata": {
        "id": "3b04f442-729d-406d-b826-654483498df6"
      },
      "outputs": [],
      "source": [
        "!curl -O -s https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/telemetry/telemetry.py\n",
        "from telemetry import enable_telemetry\n",
        "\n",
        "client = enable_telemetry(client, \"00-quick-start\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d12b707c-e89d-4b43-bee5-edb1beb84839",
      "metadata": {
        "id": "d12b707c-e89d-4b43-bee5-edb1beb84839"
      },
      "source": [
        "### Test the Client\n",
        "Before you continue, confirm that the client has connected with this test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c618eb",
      "metadata": {
        "id": "25c618eb"
      },
      "outputs": [],
      "source": [
        "print(client.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e1e6d8",
      "metadata": {
        "id": "61e1e6d8"
      },
      "source": [
        "## Index some test data\n",
        "\n",
        "Our client is set up and connected to our Elastic deployment.\n",
        "Now we need some data to test out the basics of Elasticsearch queries.\n",
        "We'll use a small index of books with the following fields:\n",
        "\n",
        "- `title`\n",
        "- `authors`\n",
        "- `publish_date`\n",
        "- `num_reviews`\n",
        "- `publisher`\n",
        "\n",
        "### Create an index\n",
        "\n",
        "First ensure that you do not have a previously created index with the name `book_index`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_OAahfg-tqrf",
      "metadata": {
        "id": "_OAahfg-tqrf"
      },
      "outputs": [],
      "source": [
        "client.indices.delete(index=\"book_index\", ignore_unavailable=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064b761a-565d-42f4-9b4a-4df4f190fd3b",
      "metadata": {
        "id": "064b761a-565d-42f4-9b4a-4df4f190fd3b"
      },
      "source": [
        "üîê NOTE: at any time you can come back to this section and run the `delete` function above to remove your index and start from scratch.\n",
        "\n",
        "Let's create an Elasticsearch index with the correct mappings for our test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc95238",
      "metadata": {
        "id": "6bc95238"
      },
      "outputs": [],
      "source": [
        "# Define the mapping\n",
        "mappings = {\n",
        "    \"properties\": {\n",
        "        \"title_vector\": {\n",
        "            \"type\": \"dense_vector\",\n",
        "            \"dims\": 384,\n",
        "            \"index\": \"true\",\n",
        "            \"similarity\": \"cosine\",\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create the index\n",
        "client.indices.create(index=\"book_index\", mappings=mappings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "075f5eb6",
      "metadata": {
        "id": "075f5eb6"
      },
      "source": [
        "### Index test data\n",
        "\n",
        "Run the following command to upload some test data, containing information about 10 popular programming books from this [dataset](https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/notebooks/search/data.json).\n",
        "`model.encode` will encode the text into a vector on the fly, using the model we initialized earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008d723e",
      "metadata": {
        "id": "008d723e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from urllib.request import urlopen\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/notebooks/search/data.json\"\n",
        "response = urlopen(url)\n",
        "books = json.loads(response.read())\n",
        "\n",
        "operations = []\n",
        "for book in books:\n",
        "    operations.append({\"index\": {\"_index\": \"book_index\"}})\n",
        "    # Transforming the title into an embedding using the model\n",
        "    book[\"title_vector\"] = model.encode(book[\"title\"]).tolist()\n",
        "    operations.append(book)\n",
        "client.bulk(index=\"book_index\", operations=operations, refresh=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd8b03e0",
      "metadata": {
        "id": "cd8b03e0"
      },
      "source": [
        "## Aside: Pretty printing Elasticsearch responses\n",
        "\n",
        "Your API calls will return hard-to-read nested JSON.\n",
        "We'll create a little function called `pretty_response` to return nice, human-readable outputs from our examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12ce2c9",
      "metadata": {
        "id": "f12ce2c9"
      },
      "outputs": [],
      "source": [
        "def pretty_response(response):\n",
        "    if len(response[\"hits\"][\"hits\"]) == 0:\n",
        "        print(\"Your search returned no results.\")\n",
        "    else:\n",
        "        for hit in response[\"hits\"][\"hits\"]:\n",
        "            id = hit[\"_id\"]\n",
        "            publication_date = hit[\"_source\"][\"publish_date\"]\n",
        "            score = hit[\"_score\"]\n",
        "            title = hit[\"_source\"][\"title\"]\n",
        "            summary = hit[\"_source\"][\"summary\"]\n",
        "            publisher = hit[\"_source\"][\"publisher\"]\n",
        "            num_reviews = hit[\"_source\"][\"num_reviews\"]\n",
        "            authors = hit[\"_source\"][\"authors\"]\n",
        "            pretty_output = f\"\\nID: {id}\\nPublication date: {publication_date}\\nTitle: {title}\\nSummary: {summary}\\nPublisher: {publisher}\\nReviews: {num_reviews}\\nAuthors: {authors}\\nScore: {score}\"\n",
        "            print(pretty_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39bdefe0",
      "metadata": {
        "id": "39bdefe0"
      },
      "source": [
        "## Making queries\n",
        "\n",
        "Now that we have indexed the books, we want to perform a semantic search for books that are similar to a given query.\n",
        "We embed the query and perform a search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Df7hwcIjYwMT",
      "metadata": {
        "id": "Df7hwcIjYwMT"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    knn={\n",
        "        \"field\": \"title_vector\",\n",
        "        \"query_vector\": model.encode(\"clear\"),\n",
        "        \"k\": 3,\n",
        "        \"num_candidates\": 3,\n",
        "    },\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LdJCpbQMeml5",
      "metadata": {
        "id": "LdJCpbQMeml5"
      },
      "source": [
        "## Filtering\n",
        "\n",
        "Filter context is mostly used for filtering structured data. For example, use filter context to answer questions like:\n",
        "\n",
        "- _Does this timestamp fall into the range 2015 to 2016?_\n",
        "- _Is the status field set to \"published\"?_\n",
        "\n",
        "Filter context is in effect whenever a query clause is passed to a filter parameter, such as the `filter` or `must_not` parameters in a `bool` query.\n",
        "\n",
        "[Learn more](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html#filter-context) about filter context in the Elasticsearch docs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dRSrPMyFf7w7",
      "metadata": {
        "id": "dRSrPMyFf7w7"
      },
      "source": [
        "### Example: Keyword Filtering\n",
        "\n",
        "This is an example of adding a keyword filter to the query.\n",
        "\n",
        "The example retrieves the top books that are similar to \"javascript books\" based on their title vectors, and also Addison-Wesley as publisher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WoE0yTchfj3A",
      "metadata": {
        "id": "WoE0yTchfj3A"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    knn={\n",
        "        \"field\": \"title_vector\",\n",
        "        \"query_vector\": model.encode(\"javascript books\"),\n",
        "        \"k\": 10,\n",
        "        \"num_candidates\": 100,\n",
        "        \"filter\": {\"term\": {\"publisher.keyword\": \"addison-wesley\"}},\n",
        "    },\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9edaa20-b8e8-4ce4-99b1-58b81de29dd5",
      "metadata": {
        "id": "d9edaa20-b8e8-4ce4-99b1-58b81de29dd5"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "# Calcula la fecha de hace dos a√±os desde hoy\n",
        "two_years_ago = (datetime.now() - timedelta(days=8*365)).strftime('%Y-%m-%d')\n",
        "\n",
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    knn={\n",
        "        \"field\": \"title_vector\",\n",
        "        \"query_vector\": model.encode(\"javascript books\"), # o la consulta que desees\n",
        "        \"k\": 10,\n",
        "        \"num_candidates\": 100,\n",
        "        \"filter\": {\n",
        "            \"range\": {\n",
        "                \"publish_date\": {\n",
        "                    \"gte\": two_years_ago,\n",
        "                    \"lte\": \"now\" # Puedes usar \"now\" para la fecha actual\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "# Asume que tienes una funci√≥n pretty_response definida\n",
        "# Ejemplo:\n",
        "# import json\n",
        "# def pretty_response(response):\n",
        "#     print(json.dumps(response.body, indent=2, ensure_ascii=False))\n",
        "\n",
        "pretty_response(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Buscar Libros por Autor ‚úçÔ∏è\n",
        "Puedes buscar utilizando el campo authors (analizado, para b√∫squedas flexibles) o authors.keyword (no analizado, para b√∫squedas exactas).\n",
        "\n",
        "B√∫squeda flexible (usando authors de tipo text)\n",
        "Esto encontrar√° libros donde \"Gabriel Garc√≠a\" aparezca en el campo de autores, incluso si hay otros autores o si el nombre tiene variaciones que el analizador pueda manejar.\n",
        "\n",
        "Python"
      ],
      "metadata": {
        "id": "vCoV9QKlgsaU"
      },
      "id": "vCoV9QKlgsaU"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "def pretty_print(response):\n",
        "    \"\"\"Funci√≥n auxiliar para imprimir respuestas JSON de forma legible.\"\"\"\n",
        "    print(json.dumps(response, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "id": "KI3FV32PeCw8"
      },
      "id": "KI3FV32PeCw8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nombre del √≠ndice\n",
        "INDEX_NAME = \"book_index\"\n",
        "\n",
        "print(\"## 1.1 B√∫squeda flexible de autor:\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"match\": {\n",
        "            \"authors\": \"ericc mathes\"\n",
        "        }\n",
        "    },\n",
        "    size=5 # Limitar a 5 resultados\n",
        ")\n",
        "pretty_response(response.body)"
      ],
      "metadata": {
        "id": "pXDmuAQUAOeD"
      },
      "id": "pXDmuAQUAOeD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## B√∫squeda flexible de autor (incluyendo solo 'title', 'authors', 'publish_date'):\")\n",
        "response_specific_fields = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"match\": {\n",
        "            \"authors\": \"eric\"\n",
        "        }\n",
        "    },\n",
        "    size=1,\n",
        "    _source=[\"title\", \"authors\", \"publish_date\"] # <--- AQU√ç SE ESPECIFICAN LOS CAMPOS A INCLUIR\n",
        ")\n",
        "pretty_print(response_specific_fields.body)"
      ],
      "metadata": {
        "id": "HSRARe8ijZyV"
      },
      "id": "HSRARe8ijZyV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"## B√∫squeda flexible de autor (excluyendo 'title_vector'):\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"match\": {\n",
        "            \"authors\": \"eric\"\n",
        "        }\n",
        "    },\n",
        "    size=1, # Limitar a 1 resultado para el ejemplo\n",
        "    _source_excludes=[\"title_vector\"] # <--- AQU√ç SE EXCLUYE EL CAMPO\n",
        ")\n",
        "pretty_print(response.body)"
      ],
      "metadata": {
        "id": "9jeRSLzakFDJ"
      },
      "id": "9jeRSLzakFDJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"## B√∫squeda por Prefijo (ej: 'eri'):\")\n",
        "query_term = \"eric\"\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"match_phrase_prefix\": {\n",
        "            \"authors\": {\n",
        "                \"query\": query_term\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "    _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response.body)\n",
        "# Deber√≠a encontrar 'eric matthes'"
      ],
      "metadata": {
        "id": "VCf3pi96kOI6"
      },
      "id": "VCf3pi96kOI6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## B√∫squeda con Fuzziness (ej: 'erric'):\")\n",
        "query_term = \"rric\"\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"match\": {\n",
        "            \"authors\": {\n",
        "                \"query\": query_term,\n",
        "                \"fuzziness\": \"AUTO\" # O un valor como 1 o 2 (distancia de Levenshtein)\n",
        "                                # \"AUTO\" genera distancias de edici√≥n basadas en la longitud del t√©rmino.\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "    _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response.body)\n",
        "# Deber√≠a encontrar 'eric matthes' si la fuzziness es adecuada."
      ],
      "metadata": {
        "id": "GfYz5iCykjI0"
      },
      "id": "GfYz5iCykjI0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## B√∫squeda con Comodines usando query_string:\")\n",
        "\n",
        "# Ejemplo para \"eri\" (como prefijo)\n",
        "query_wildcard_prefix = \"eri*\"\n",
        "print(f\"--- Buscando con: {query_wildcard_prefix} ---\")\n",
        "response_prefix = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"query_string\": {\n",
        "            \"query\": query_wildcard_prefix,\n",
        "            \"default_field\": \"authors\"\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "     _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response_prefix.body)\n",
        "\n"
      ],
      "metadata": {
        "id": "wTtxiyr3k5HG"
      },
      "id": "wTtxiyr3k5HG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo para \"ric\" (como parte del t√©rmino)\n",
        "query_wildcard_contains = \"*ric*\" # Podr√≠a ser \"*ric\" si solo buscas al final\n",
        "print(f\"\\n--- Buscando con: {query_wildcard_contains} ---\")\n",
        "response_contains = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"query_string\": {\n",
        "            \"query\": query_wildcard_contains,\n",
        "            \"default_field\": \"authors\"\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "     _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response_contains.body)\n",
        "# Esta consulta ('*ric*') deber√≠a encontrar 'eric matthes'."
      ],
      "metadata": {
        "id": "DyA9wFiZk7D-"
      },
      "id": "DyA9wFiZk7D-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## B√∫squeda con simple_query_string:\")\n",
        "\n",
        "# Para prefijo \"eri\"\n",
        "query_sqs_prefix = \"eri*\"\n",
        "print(f\"--- Buscando con simple_query_string (prefijo): {query_sqs_prefix} ---\")\n",
        "response_sqs_prefix = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"simple_query_string\": {\n",
        "            \"query\": query_sqs_prefix,\n",
        "            \"fields\": [\"authors\"], # Especifica los campos donde buscar\n",
        "            \"default_operator\": \"AND\"\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "     _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response_sqs_prefix.body)\n",
        "\n",
        "\n",
        "# Para typo \"erric\" (usando fuzziness)\n",
        "query_sqs_fuzzy = \"erric~1\" # El ~1 indica una distancia de edici√≥n de 1\n",
        "print(f\"\\n--- Buscando con simple_query_string (fuzziness): {query_sqs_fuzzy} ---\")\n",
        "response_sqs_fuzzy = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"simple_query_string\": {\n",
        "            \"query\": query_sqs_fuzzy,\n",
        "            \"fields\": [\"authors\"],\n",
        "            \"default_operator\": \"AND\"\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "     _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response_sqs_fuzzy.body)\n",
        "\n",
        "\n",
        "# Para \"ric\" como parte de \"eric\"\n",
        "query_sqs_contains = \"*ric*\"\n",
        "print(f\"\\n--- Buscando con simple_query_string (contiene): {query_sqs_contains} ---\")\n",
        "response_sqs_contains = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"simple_query_string\": {\n",
        "            \"query\": query_sqs_contains,\n",
        "            \"fields\": [\"authors\"],\n",
        "            \"default_operator\": \"AND\"\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "     _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response_sqs_contains.body)"
      ],
      "metadata": {
        "id": "PIMdjcTZlZH6"
      },
      "id": "PIMdjcTZlZH6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## Probando con query_string para '*ric*':\")\n",
        "query_term = \"*ric*\"\n",
        "response_qs = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"query_string\": {\n",
        "            \"query\": query_term,\n",
        "            \"fields\": [\"authors\"], # Puedes usar 'fields' o 'default_field'\n",
        "            # \"analyze_wildcard\": False # Es el valor por defecto, pero puedes ser expl√≠cito\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "     _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response_qs.body)"
      ],
      "metadata": {
        "id": "AHYLUeh1mVMH"
      },
      "id": "AHYLUeh1mVMH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## Probando simple_query_string simplificada para '*ric*':\")\n",
        "query_term = \"*ric*\"\n",
        "response_sqs_simple = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"simple_query_string\": {\n",
        "            \"query\": query_term,\n",
        "            \"fields\": [\"authors\"]\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "     _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response_sqs_simple.body)"
      ],
      "metadata": {
        "id": "uEc6tIWXmb-H"
      },
      "id": "uEc6tIWXmb-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GET book_index/_termvectors/_NVoQJcBYS182ubtUI05\n",
        "{\n",
        "  \"fields\": [\"authors\"]\n",
        "}"
      ],
      "metadata": {
        "id": "5lwJM3LWmlOp"
      },
      "id": "5lwJM3LWmlOp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## 1.2 B√∫squeda exacta de autor:\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"term\": {\n",
        "            \"authors.keyword\": \"david\"\n",
        "        }\n",
        "    },\n",
        "    size=5\n",
        ")\n",
        "pretty_response(response.body)"
      ],
      "metadata": {
        "id": "VP7eIX0chwqz"
      },
      "id": "VP7eIX0chwqz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## 2. Agregaci√≥n de autores √∫nicos:\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    size=0,  # No necesitamos los documentos, solo la agregaci√≥n\n",
        "    aggs={\n",
        "        \"unique_authors\": {\n",
        "            \"terms\": {\n",
        "                \"field\": \"authors.keyword\",\n",
        "                \"size\": 20  # N√∫mero de autores √∫nicos a mostrar\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")\n",
        "pretty_print(response.body['aggregations'])"
      ],
      "metadata": {
        "id": "Hkn37WmeiqMs"
      },
      "id": "Hkn37WmeiqMs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## 3. Destacar t√©rminos en autores:\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"match\": {\n",
        "            \"authors\": \"Martin\" # Buscar libros que tengan \"Martin\" en los autores\n",
        "        }\n",
        "    },\n",
        "    highlight={\n",
        "        \"fields\": {\n",
        "            \"authors\": {} # Configuraci√≥n de resaltado por defecto para el campo 'authors'\n",
        "        }\n",
        "    },\n",
        "    size=3,\n",
        "    _source_excludes=[\"title_vector\"]\n",
        ")\n",
        "pretty_print(response.body)"
      ],
      "metadata": {
        "id": "Uf_XxExzi7aq"
      },
      "id": "Uf_XxExzi7aq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## 4. Libros con m√°s de un autor:\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"bool\": {\n",
        "            \"filter\": {\n",
        "                \"script\": {\n",
        "                    \"script\": {\n",
        "                        \"source\": \"doc['authors.keyword'].size() > params.count\",\n",
        "                        \"params\": {\n",
        "                            \"count\": 1\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "    _source=[\"title\", \"authors\"] # Solo traer t√≠tulo y autores\n",
        ")\n",
        "pretty_print(response.body)"
      ],
      "metadata": {
        "id": "z15H7q74nrBv"
      },
      "id": "z15H7q74nrBv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## 5. Libros con m√°s de dos autores:\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    query={\n",
        "        \"bool\": {\n",
        "            \"filter\": {\n",
        "                \"script\": {\n",
        "                    \"script\": {\n",
        "                        \"source\": \"doc['authors.keyword'].size() > params.count\",\n",
        "                        \"params\": {\n",
        "                            \"count\": 2\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "    _source=[\"title\", \"authors\"]\n",
        ")\n",
        "pretty_print(response.body)"
      ],
      "metadata": {
        "id": "5zX3Uit9nxw4"
      },
      "id": "5zX3Uit9nxw4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n## 6. Facet por cantidad de autores:\")\n",
        "response = client.search(\n",
        "    index=INDEX_NAME,\n",
        "    size=0, # No necesitamos los documentos, solo la agregaci√≥n\n",
        "    aggs={\n",
        "        \"authors_count_facet\": {\n",
        "            \"terms\": {\n",
        "                \"script\": {\n",
        "                    \"source\": \"doc['authors.keyword'].size()\", # Devuelve el n√∫mero de autores\n",
        "                    \"lang\": \"painless\"\n",
        "                },\n",
        "                \"size\": 10 # Muestra los 10 conteos de autores m√°s comunes\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")\n",
        "pretty_print(response.body['aggregations'])"
      ],
      "metadata": {
        "id": "h4CPifESn09I"
      },
      "id": "h4CPifESn09I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "# Asume que 'client' ya est√° inicializado\n",
        "# client = Elasticsearch(...)\n",
        "# INDEX_NAME = \"book_index\" # O un nuevo nombre como \"book_index_ngram\"\n",
        "\n",
        "# 1. Definir settings y mappings\n",
        "index_settings = {\n",
        "    \"analysis\": {\n",
        "        \"analyzer\": {\n",
        "            \"custom_trigram_analyzer\": {\n",
        "                \"tokenizer\": \"standard\",\n",
        "                \"filter\": [\n",
        "                    \"lowercase\",\n",
        "                    \"trigram_token_filter\"\n",
        "                ]\n",
        "            }\n",
        "        },\n",
        "        \"filter\": {\n",
        "            \"trigram_token_filter\": {\n",
        "                \"type\": \"ngram\",\n",
        "                \"min_gram\": 3,\n",
        "                \"max_gram\": 3\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "index_mappings = {\n",
        "    \"properties\": {\n",
        "        \"authors\": {\n",
        "            \"type\": \"text\",\n",
        "            \"analyzer\": \"custom_trigram_analyzer\",\n",
        "            \"fields\": {\n",
        "                \"keyword\": {\n",
        "                    \"type\": \"keyword\",\n",
        "                    \"ignore_above\": 256\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"num_reviews\": {\"type\": \"long\"},\n",
        "        \"publish_date\": {\"type\": \"date\"},\n",
        "        \"publisher\": {\n",
        "            \"type\": \"text\",\n",
        "            \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
        "        },\n",
        "        \"summary\": {\n",
        "            \"type\": \"text\",\n",
        "            \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
        "        },\n",
        "        \"title\": {\n",
        "            \"type\": \"text\",\n",
        "            \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}\n",
        "        },\n",
        "        \"title_vector\": {\n",
        "            \"type\": \"dense_vector\",\n",
        "            \"dims\": 384,\n",
        "            \"index\": True,\n",
        "            \"similarity\": \"cosine\",\n",
        "            \"index_options\": {\"type\": \"int8_hnsw\", \"m\": 16, \"ef_construction\": 100}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# (Opcional) Nombre del nuevo √≠ndice, o puedes usar el mismo si lo vas a borrar primero\n",
        "NEW_INDEX_NAME = \"book_index_trigram\" # O usa tu INDEX_NAME original\n",
        "\n",
        "# 2. (Opcional) Borrar el √≠ndice antiguo si vas a reutilizar el nombre y est√°s en desarrollo\n",
        "if client.indices.exists(index=NEW_INDEX_NAME):\n",
        "    print(f\"Borrando √≠ndice existente: {NEW_INDEX_NAME}\")\n",
        "    client.indices.delete(index=NEW_INDEX_NAME)\n",
        "\n",
        "# 3. Crear el nuevo √≠ndice con la configuraci√≥n y mapeo\n",
        "print(f\"Creando √≠ndice: {NEW_INDEX_NAME}\")\n",
        "client.indices.create(\n",
        "    index=NEW_INDEX_NAME,\n",
        "    settings=index_settings,\n",
        "    mappings=index_mappings\n",
        ")\n",
        "print(\"√çndice creado con √©xito.\")\n",
        "\n",
        "# 4. Re-poblar tus datos\n",
        "#    Esto depender√° de c√≥mo cargas tus datos originalmente.\n",
        "#    Por ejemplo, si tienes una lista de documentos:\n",
        "#    docs = [\n",
        "#        {\"authors\": [\"eric matthes\"], \"title\": \"Python Crash Course\", ...},\n",
        "#        ...\n",
        "#    ]\n",
        "#    for i, doc in enumerate(docs):\n",
        "#        client.index(index=NEW_INDEX_NAME, id=i, document=doc)\n",
        "#    print(f\"{len(docs)} documentos indexados.\")\n",
        "\n",
        "# Si tienes un √≠ndice existente (ej. \"book_index\") y quieres mover los datos:\n",
        "print(\"Iniciando reindexaci√≥n...\")\n",
        "client.reindex(\n",
        "     body={\n",
        "         \"source\": {\"index\": \"book_index\"}, # Tu √≠ndice original\n",
        "         \"dest\": {\"index\": NEW_INDEX_NAME}\n",
        "     },\n",
        "     request_timeout=300 # Aumenta el timeout si es necesario\n",
        " )\n",
        "print(\"Reindexaci√≥n completada.\")"
      ],
      "metadata": {
        "id": "9TCCSVaRqITO"
      },
      "id": "9TCCSVaRqITO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asume que 'client' est√° configurado y NEW_INDEX_NAME es el √≠ndice con N-grams\n",
        "# (y que has re-poblado los datos en este nuevo √≠ndice)\n",
        "\n",
        "# Ejemplo: Buscar \"ric\"\n",
        "search_term = \"erric\"\n",
        "\n",
        "print(f\"\\nBuscando '{search_term}' en el campo 'authors' (N-gram):\")\n",
        "response = client.search(\n",
        "    index=NEW_INDEX_NAME, # Aseg√∫rate de consultar el √≠ndice correcto\n",
        "    query={\n",
        "        \"match\": {\n",
        "            \"authors\": search_term\n",
        "        }\n",
        "    },\n",
        "    size=5,\n",
        "    _source=[\"title\", \"authors\"]\n",
        ")\n",
        "# from your_previous_code import pretty_print # si la tienes definida\n",
        "# pretty_print(response.body)\n",
        "print(json.dumps(response.body, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Esto deber√≠a encontrar \"eric matthes\" porque \"eric\" genera el trigrama \"ric\",\n",
        "# y el t√©rmino de b√∫squeda \"ric\" (al ser de longitud 3) se convierte en el token \"ric\"."
      ],
      "metadata": {
        "id": "XGSBV3-Mqoza"
      },
      "id": "XGSBV3-Mqoza",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [01-keyword-querying-filtering.ipynb](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/01-keyword-querying-filtering.ipynb#scrollTo=wMbAEseBzD5S)\n",
        "## Querying\n",
        "üîê NOTE: to run the queries that follow you need the `book_index` dataset from our [quick start](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/00-quick-start.ipynb). If you haven't worked through the quick start, please follow the steps described there to create an Elasticsearch deployment with the dataset in it, and then come back to run the queries here.\n",
        "\n",
        "In the query context, a query clause answers the question _‚ÄúHow well does this document match this query clause?‚Äù_. In addition to deciding whether or not the document matches, the query clause also calculates a relevance score in the `_score `metadata field.\n",
        "\n",
        "### Full text queries\n",
        "\n",
        "Full text queries enable you to search analyzed text fields such as the body of an email. The query string is processed using the same analyzer that was applied to the field during indexing.\n",
        "\n",
        "* **match**.\n",
        "    The standard query for performing full text queries, including fuzzy matching and phrase or proximity queries.\n",
        "* **multi-match**.\n",
        "    The multi-field version of the match query.\n",
        "\n",
        "##Match query"
      ],
      "metadata": {
        "id": "lAtOxK_P0Gv8"
      },
      "id": "lAtOxK_P0Gv8"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\", query={\"match\": {\"summary\": {\"query\": \"program\"}}}\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "ahoXa_dY0Fvk"
      },
      "id": "ahoXa_dY0Fvk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multi-Match query"
      ],
      "metadata": {
        "id": "t2E9YOTU8vh2"
      },
      "id": "t2E9YOTU8vh2"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    query={\"multi_match\": {\"query\": \"programming\", \"fields\": [\"summary\", \"title\"]}},\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "CUAq7_RK0vGY"
      },
      "id": "CUAq7_RK0vGY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Individual fields can be boosted with the caret (^) notation. Note in the following query how the score of the results that have \"JavaScript\" in their title is multiplied."
      ],
      "metadata": {
        "id": "4aka0F430-Xx"
      },
      "id": "4aka0F430-Xx"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    query={\"multi_match\": {\"query\": \"javascript\", \"fields\": [\"summary\", \"title^3\"]}},\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "DYEGqbfg0_T5"
      },
      "id": "DYEGqbfg0_T5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Term-level Queries\n",
        "You can use term-level queries to find documents based on precise values in structured data. Examples of structured data include date ranges, IP addresses, prices, or product IDs.\n",
        "\n",
        "### Term search\n",
        "Returns document that contain exactly the search term."
      ],
      "metadata": {
        "id": "Y1qTfmKK1OSL"
      },
      "id": "Y1qTfmKK1OSL"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\", query={\"term\": {\"publisher.keyword\": \"addison-wesley\"}}\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "4jSO4tKC1SSL"
      },
      "id": "4jSO4tKC1SSL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\", query={\"term\": {\"authors.keyword\": \"david thomas\"}}\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "eCNs35TH1g_N"
      },
      "id": "eCNs35TH1g_N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Range search\n",
        "Returns documents that contain terms within a provided range.\n",
        "\n",
        "The following example returns books that have at least 45 reviews."
      ],
      "metadata": {
        "id": "_db__E6y1vUu"
      },
      "id": "_db__E6y1vUu"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\", query={\"range\": {\"num_reviews\": {\"gte\": 45}}}\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "9lV65W5W1u2O"
      },
      "id": "9lV65W5W1u2O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prefix search\n",
        "\n",
        "Returns documents that contain a specific prefix in a provided field.\n",
        "\n",
        "[Read more](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-prefix-query.html)"
      ],
      "metadata": {
        "id": "6N-_j4nB1623"
      },
      "id": "6N-_j4nB1623"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\", query={\"prefix\": {\"title\": {\"value\": \"jav\"}}}\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "ZRg7gytM17Io"
      },
      "id": "ZRg7gytM17Io",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fuzzy search\n",
        "\n",
        "Returns documents that contain terms similar to the search term, as measured by a Levenshtein edit distance.\n",
        "\n",
        "An edit distance is the number of one-character changes needed to turn one term into another. These changes can include:\n",
        "\n",
        "* Changing a character (box ‚Üí fox)\n",
        "* Removing a character (black ‚Üí lack)\n",
        "* Inserting a character (sic ‚Üí sick)\n",
        "* Transposing two adjacent characters (act ‚Üí cat)\n",
        "\n",
        "[Read more](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-fuzzy-query.html)"
      ],
      "metadata": {
        "id": "_wW7m7Ni2ZIC"
      },
      "id": "_wW7m7Ni2ZIC"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4OuE3uHd9Anf"
      },
      "id": "4OuE3uHd9Anf"
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\", query={\"fuzzy\": {\"authors\": {\"value\": \"ric\"}}}\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "metadata": {
        "id": "ii_W7e3P2cYL"
      },
      "id": "ii_W7e3P2cYL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSgj1anGzD5S"
      },
      "source": [
        "## Combining Query Conditions\n",
        "\n",
        "Compound queries wrap other compound or leaf queries, either to combine their results and scores, or to change their behaviour. They also allow you to switch from query to filter context, but that will be covered later in the Filtering section."
      ],
      "id": "bSgj1anGzD5S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7do0lmxA_v25"
      },
      "source": [
        "#### bool.must (AND)\n",
        "The clauses must appear in matching documents and will contribute to the score. This effectively performs an \"AND\" logical operation on the given sub-queries."
      ],
      "id": "7do0lmxA_v25"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_C-JHRQFDl7"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    query={\n",
        "        \"bool\": {\n",
        "            \"must\": [\n",
        "                {\"term\": {\"publisher.keyword\": \"addison-wesley\"}},\n",
        "                {\"term\": {\"authors.keyword\": \"richard helm\"}},\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "id": "8_C-JHRQFDl7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNlncytRIl9h"
      },
      "source": [
        "#### bool.should (OR)\n",
        "\n",
        "The clause should appear in the matching document. This performs an \"OR\" logical operation on the given sub-queries."
      ],
      "id": "eNlncytRIl9h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRm9T1vfIsmF"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    query={\n",
        "        \"bool\": {\n",
        "            \"should\": [\n",
        "                {\"term\": {\"publisher.keyword\": \"addison-wesley\"}},\n",
        "                {\"term\": {\"authors.keyword\": \"douglas crockford\"}},\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "id": "GRm9T1vfIsmF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG9TYqL-8H29"
      },
      "source": [
        "## Filtering\n",
        "\n",
        "In a filter context, a query clause answers the question *‚ÄúDoes this document match this query clause?‚Äù* The answer is a simple Yes or No‚Äâ‚Äî‚Äâno scores are calculated. Filter context is mostly used for filtering structured data, for example:\n",
        "* Does this `timestamp` fall into the range 2015 to 2016?\n",
        "* Is the `status` field set to `\"published\"`?\n",
        "\n",
        "Filter context is in effect whenever a query clause is passed to a `filter` parameter, such as the `filter` or `must_not` parameters in the `bool` query.\n",
        "\n",
        "[Read more](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html)"
      ],
      "id": "PG9TYqL-8H29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGTFXUIkJG4t"
      },
      "source": [
        "### bool.filter\n",
        "\n",
        "The clause (query) must appear for the document to be included in the results. Unlike query context searches such as `term`, `bool.must` or `bool.should`, a matching `score` isn't calculated because filter clauses are executed in filter context."
      ],
      "id": "PGTFXUIkJG4t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RH0OALLJPHv"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    query={\"bool\": {\"filter\": [{\"term\": {\"publisher.keyword\": \"prentice hall\"}}]}},\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "id": "6RH0OALLJPHv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGZMYxhjzD5T"
      },
      "source": [
        "### bool.must_not\n",
        "The clause (query) must not appear in the matching documents. Because this query also runs in filter context, no scores are calculated; the filter just determines if a document is included in the results or not."
      ],
      "id": "UGZMYxhjzD5T"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8mtwx-QzD5T"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    query={\"bool\": {\"must_not\": [{\"range\": {\"num_reviews\": {\"lte\": 45}}}]}},\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "id": "M8mtwx-QzD5T"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzFukfabzD5U"
      },
      "source": [
        "### Using Filters with Queries\n",
        "Filters are often added to search queries with the intention of limiting the search to a subset of the documents. A filter can cleanly eliminate documents from a search, without altering the relevance scores of the results.\n",
        "\n",
        "The next example returns books that have the word \"javascript\" in their title, only among the books that have more than 45 reviews."
      ],
      "id": "pzFukfabzD5U"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yurVfBtzD5W"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    query={\n",
        "        \"bool\": {\n",
        "            \"must\": [{\"match\": {\"title\": {\"query\": \"javascript\"}}}],\n",
        "            \"must_not\": [{\"range\": {\"num_reviews\": {\"lte\": 45}}}],\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "pretty_response(response)"
      ],
      "id": "2yurVfBtzD5W"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s49gpkvZ7q53"
      },
      "source": [
        "# 02 Hybrid Search using RRF\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/02-hybrid-search.ipynb)\n",
        "\n",
        "In this example we'll use the reciprocal rank fusion algorithm to combine the results of BM25 and kNN semantic search.\n",
        "We'll use the same dataset we used in our [quickstart](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/00-quick-start.ipynb) guide.\n",
        "\n",
        "You can use RRF for hybrid search out of the box, without any additional configuration. This example demonstrates how RRF ranking works at a basic level."
      ],
      "id": "s49gpkvZ7q53"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaTFHLJC-Mgi"
      },
      "source": [
        "# Install packages and initialize the Elasticsearch Python client\n",
        "\n",
        "To get started, we'll need to connect to our Elastic deployment using the Python client.\n",
        "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
        "\n",
        "First we need to `pip` install the packages we need for this example."
      ],
      "id": "gaTFHLJC-Mgi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Q1p2C9-wce"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \"elasticsearch<9\" sentence-transformers==2.7.0"
      ],
      "id": "K9Q1p2C9-wce"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEzq2Z1wBs3M"
      },
      "source": [
        "Next we need to import the `elasticsearch` module and the `getpass` module.\n",
        "`getpass` is part of the Python standard library and is used to securely prompt for credentials."
      ],
      "id": "gEzq2Z1wBs3M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP_GTVRi-d96"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from getpass import getpass\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "id": "uP_GTVRi-d96"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMSePFiZCRqX"
      },
      "source": [
        "Now we can instantiate the Python Elasticsearch client.\n",
        "First we prompt the user for their password and Cloud ID.\n",
        "\n",
        "üîê NOTE: `getpass` enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory.\n",
        "\n",
        "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class."
      ],
      "id": "AMSePFiZCRqX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0MdAZ53CdKL"
      },
      "outputs": [],
      "source": [
        "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
        "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
        "\n",
        "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
        "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    # For local development\n",
        "    # hosts=[\"http://localhost:9200\"]\n",
        "    cloud_id=ELASTIC_CLOUD_ID,\n",
        "    api_key=ELASTIC_API_KEY,\n",
        ")"
      ],
      "id": "h0MdAZ53CdKL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lryPNhVH-Ntw"
      },
      "source": [
        "### Enable Telemetry\n",
        "\n",
        "Knowing that you are using this notebook helps us decide where to invest our efforts to improve our products. We would like to ask you that you run the following code to let us gather anonymous usage statistics. See [telemetry.py](https://github.com/elastic/elasticsearch-labs/blob/main/telemetry/telemetry.py) for details. Thank you!"
      ],
      "id": "lryPNhVH-Ntw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba5BRp8o-Ntw"
      },
      "outputs": [],
      "source": [
        "!curl -O -s https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/telemetry/telemetry.py\n",
        "from telemetry import enable_telemetry\n",
        "\n",
        "client = enable_telemetry(client, \"02-hybrid-search\")"
      ],
      "id": "Ba5BRp8o-Ntw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRHbecNeEDL3"
      },
      "source": [
        "### Test the Client\n",
        "Before you continue, confirm that the client has connected with this test."
      ],
      "id": "bRHbecNeEDL3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdiUKqZbEKfF"
      },
      "outputs": [],
      "source": [
        "print(client.info())"
      ],
      "id": "rdiUKqZbEKfF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enHQuT57DhD1"
      },
      "source": [
        "Refer to https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect to a self-managed deployment.\n",
        "\n",
        "Read https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect using API keys.\n"
      ],
      "id": "enHQuT57DhD1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgWDMgf9NkHL"
      },
      "source": [
        "## Pretty printing Elasticsearch responses\n",
        "\n",
        "Let's add a helper function to print Elasticsearch responses in a readable format. This function is similar to the one that was used in the [quickstart](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/00-quick-start.ipynb) guide."
      ],
      "id": "WgWDMgf9NkHL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kppwUo1X-Ntx"
      },
      "outputs": [],
      "source": [
        "def pretty_response(response):\n",
        "    if len(response[\"hits\"][\"hits\"]) == 0:\n",
        "        print(\"Your search returned no results.\")\n",
        "    else:\n",
        "        for idx, hit in enumerate(response[\"hits\"][\"hits\"], start=1):\n",
        "            id = hit[\"_id\"]\n",
        "            publication_date = hit[\"_source\"][\"publish_date\"]\n",
        "            score = hit[\"_score\"]\n",
        "            title = hit[\"_source\"][\"title\"]\n",
        "            summary = hit[\"_source\"][\"summary\"]\n",
        "            pretty_output = f\"\\nID: {id}\\nPublication date: {publication_date}\\nTitle: {title}\\nSummary: {summary}\\nRank: {idx}\\nScore: {score}\"\n",
        "            print(pretty_output)"
      ],
      "id": "kppwUo1X-Ntx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrBCHdH1u8Wd"
      },
      "source": [
        "# Querying Documents with Hybrid Search\n",
        "\n",
        "üîê NOTE: Before you can run the query in this section, you need the `book_index` dataset from our [quick start](https://github.com/elastic/elasticsearch-labs/blob/main/notebooks/search/00-quick-start.ipynb). If you haven't worked through the quick start, please follow the steps described there to create an Elasticsearch deployment with the dataset in it, and then come back to run the query here.\n",
        "\n",
        "Now we need to perform a query using two different search strategies:\n",
        "- Semantic search using the \"all-MiniLM-L6-v2\" embedding model\n",
        "- Keyword search using the \"title\" field\n",
        "\n",
        "We then use [Reciprocal Rank Fusion (RRF)](https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html) to balance the scores to provide a final list of documents, ranked in order of relevance. RRF is a ranking algorithm for combining results from different information retrieval strategies.\n",
        "\n",
        "Note: With the retriever API, _score contains the document‚Äôs relevance score, and the rank is simply the position in the results (first result is rank 1, etc.)."
      ],
      "id": "MrBCHdH1u8Wd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BLF6jB_-Ntx"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"book_index\",\n",
        "    size=3,\n",
        "    retriever={\n",
        "        \"rrf\": {\n",
        "            \"retrievers\": [\n",
        "                {\"standard\": {\"query\": {\"match\": {\"summary\": \"python programming\"}}}},\n",
        "                {\n",
        "                    \"knn\": {\n",
        "                        \"field\": \"title_vector\",\n",
        "                        \"query_vector\": model.encode(\"python programming\").tolist(),\n",
        "                        \"k\": 3,\n",
        "                        \"num_candidates\": 3,\n",
        "                    }\n",
        "                },\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    source_excludes=[\"title_vector\"] # <--- AQU√ç SE EXCLUYE EL CAMPO\n",
        ")\n",
        "pretty_response(response)\n",
        "pretty_print(response.body)"
      ],
      "id": "6BLF6jB_-Ntx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRTiXBlKBEd8"
      },
      "source": [
        "# 03 Semantic Search using ELSER v2 text expansion\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elastic/elasticsearch-labs/blob/main/notebooks/search/03-ELSER.ipynb)\n",
        "\n",
        "\n",
        "Learn how to use the [ELSER](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-elser.html) for text expansion-powered semantic search.\n",
        "\n",
        "**`Note:`** This notebook demonstrates how to use ELSER model `.elser_model_2` model which offers an improved retrieval accuracy.\n",
        "\n",
        "If you have set up an index with ELSER model `.elser_model_1`, and would like to upgrade to ELSER v2 model - `.elser_model_2`, Please follow instructions from the notebook on [how to upgrade an index to use elser model](../model-upgrades/upgrading-index-to-use-elser.ipynb)"
      ],
      "id": "zRTiXBlKBEd8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLgJ7gUcBEd9"
      },
      "source": [
        "# Install and Connect\n",
        "\n",
        "To get started, we'll need to connect to our Elastic deployment using the Python client.\n",
        "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
        "\n",
        "First we need to `pip` install the following packages:\n",
        "\n",
        "- `elasticsearch`\n"
      ],
      "id": "fLgJ7gUcBEd9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9pTQO03BEd9"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \"elasticsearch<9\""
      ],
      "id": "n9pTQO03BEd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYvhAg6OBEd9"
      },
      "source": [
        "Next, we need to import the modules we need.\n",
        "üîê NOTE: `getpass` enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory."
      ],
      "id": "cYvhAg6OBEd9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTY1UKDSBEd9"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch, helpers, exceptions\n",
        "from urllib.request import urlopen\n",
        "from getpass import getpass\n",
        "import json\n",
        "import time"
      ],
      "id": "wTY1UKDSBEd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19oT5p-8BEd9"
      },
      "source": [
        "Now we can instantiate the Python Elasticsearch client.\n",
        "\n",
        "First we prompt the user for their password and Cloud ID.\n",
        "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class."
      ],
      "id": "19oT5p-8BEd9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uFIFVsBBEd9"
      },
      "outputs": [],
      "source": [
        "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id\n",
        "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
        "\n",
        "# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key\n",
        "ELASTIC_API_KEY = getpass(\"Elastic Api Key: \")\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    # For local development\n",
        "    # hosts=[\"http://localhost:9200\"]\n",
        "    cloud_id=ELASTIC_CLOUD_ID,\n",
        "    api_key=ELASTIC_API_KEY,\n",
        ")"
      ],
      "id": "-uFIFVsBBEd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awAzHxJzBBfC"
      },
      "source": [
        "### Enable Telemetry\n",
        "\n",
        "Knowing that you are using this notebook helps us decide where to invest our efforts to improve our products. We would like to ask you that you run the following code to let us gather anonymous usage statistics. See [telemetry.py](https://github.com/elastic/elasticsearch-labs/blob/main/telemetry/telemetry.py) for details. Thank you!"
      ],
      "id": "awAzHxJzBBfC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpuigORbBBfC"
      },
      "outputs": [],
      "source": [
        "!curl -O -s https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/telemetry/telemetry.py\n",
        "from telemetry import enable_telemetry\n",
        "\n",
        "client = enable_telemetry(client, \"03-ELSER\")"
      ],
      "id": "LpuigORbBBfC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFhHF4W6BEd9"
      },
      "source": [
        "### Test the Client\n",
        "Before you continue, confirm that the client has connected with this test."
      ],
      "id": "BFhHF4W6BEd9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUVn27w0BEd9"
      },
      "outputs": [],
      "source": [
        "print(client.info())"
      ],
      "id": "jUVn27w0BEd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJg8C5S3BEd-"
      },
      "source": [
        "Refer to https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect to a self-managed deployment.\n",
        "\n",
        "Read https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect using API keys.\n"
      ],
      "id": "oJg8C5S3BEd-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FfaFWw6BBfD"
      },
      "source": [
        "# Download and Deploy ELSER Model\n",
        "\n",
        "In this example, we are going to download and deploy the ELSER model in our ML node. Make sure you have an ML node in order to run the ELSER model."
      ],
      "id": "8FfaFWw6BBfD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ_2jyjJBBfD"
      },
      "outputs": [],
      "source": [
        "# delete model if already downloaded and deployed\n",
        "try:\n",
        "    client.ml.delete_trained_model(model_id=\".elser_model_2\", force=True)\n",
        "    print(\"Model deleted successfully, We will proceed with creating one\")\n",
        "except exceptions.NotFoundError:\n",
        "    print(\"Model doesn't exist, but We will proceed with creating one\")\n",
        "\n",
        "# Creates the ELSER model configuration. Automatically downloads the model if it doesn't exist.\n",
        "client.ml.put_trained_model(\n",
        "    model_id=\".elser_model_2\", input={\"field_names\": [\"text_field\"]}\n",
        ")"
      ],
      "id": "yQ_2jyjJBBfD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVBTCDjHBBfD"
      },
      "source": [
        "The above command will download the ELSER model. This will take a few minutes to complete. Use the following command to check the status of the model download."
      ],
      "id": "CVBTCDjHBBfD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0blN_zbBBfD"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    status = client.ml.get_trained_models(\n",
        "        model_id=\".elser_model_2\", include=\"definition_status\"\n",
        "    )\n",
        "\n",
        "    if status[\"trained_model_configs\"][0][\"fully_defined\"]:\n",
        "        print(\"ELSER Model is downloaded and ready to be deployed.\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"ELSER Model is downloaded but not ready to be deployed.\")\n",
        "    time.sleep(5)"
      ],
      "id": "q0blN_zbBBfD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixRYv1TlBBfD"
      },
      "source": [
        "Once the model is downloaded, we can deploy the model in our ML node. Use the following command to deploy the model."
      ],
      "id": "ixRYv1TlBBfD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6omz3D6oBBfE"
      },
      "outputs": [],
      "source": [
        "# Start trained model deployment if not already deployed\n",
        "client.ml.start_trained_model_deployment(\n",
        "    model_id=\".elser_model_2\", number_of_allocations=1, wait_for=\"starting\"\n",
        ")\n",
        "\n",
        "while True:\n",
        "    status = client.ml.get_trained_models_stats(\n",
        "        model_id=\".elser_model_2\",\n",
        "    )\n",
        "    if status[\"trained_model_stats\"][0][\"deployment_stats\"][\"state\"] == \"started\":\n",
        "        print(\"ELSER Model has been successfully deployed.\")\n",
        "        break\n",
        "    else:\n",
        "        print(\"ELSER Model is currently being deployed.\")\n",
        "    time.sleep(5)"
      ],
      "id": "6omz3D6oBBfE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMeZ7k9cBBfE"
      },
      "source": [
        "This also will take a few minutes to complete."
      ],
      "id": "OMeZ7k9cBBfE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmELvr_JK_22"
      },
      "source": [
        "# Indexing Documents with ELSER\n",
        "\n",
        "In order to use ELSER on our Elastic Cloud deployment we'll need to create an ingest pipeline that contains an inference processor that runs the ELSER model.\n",
        "Let's add that pipeline using the [`put_pipeline`](https://www.elastic.co/guide/en/elasticsearch/reference/master/put-pipeline-api.html) method."
      ],
      "id": "EmELvr_JK_22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhRng99KLQsd"
      },
      "outputs": [],
      "source": [
        "client.ingest.put_pipeline(\n",
        "    id=\"elser-ingest-pipeline\",\n",
        "    description=\"Ingest pipeline for ELSER\",\n",
        "    processors=[\n",
        "        {\n",
        "            \"inference\": {\n",
        "                \"model_id\": \".elser_model_2\",\n",
        "                \"input_output\": [\n",
        "                    {\"input_field\": \"plot\", \"output_field\": \"plot_embedding\"}\n",
        "                ],\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        ")"
      ],
      "id": "XhRng99KLQsd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wCH7YHLNW3i"
      },
      "source": [
        "Let's note a few important parameters from that API call:\n",
        "\n",
        "- `inference`: A processor that performs inference using a machine learning model.\n",
        "- `model_id`: Specifies the ID of the machine learning model to be used. In this example, the model ID is set to `.elser_model_2`.\n",
        "- `input_output`: Specifies input and output fields\n",
        "- `input_field`: Field name from which the `sparse_vector` representation are created.\n",
        "- `output_field`:  Field name which contains inference results."
      ],
      "id": "0wCH7YHLNW3i"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF_wxIAhD07a"
      },
      "source": [
        "## Create index\n",
        "\n",
        "To use the ELSER model at index time, we'll need to create an index mapping that supports a [`text_expansion`](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-text-expansion-query.html) query.\n",
        "The mapping includes a field of type [`sparse_vector`](https://www.elastic.co/guide/en/elasticsearch/reference/master/sparse-vector.html)  to work with our feature vectors of interest.\n",
        "This field contains the token-weight pairs the ELSER model created based on the input text.\n",
        "\n",
        "Let's create an index named `elser-example-movies` with the mappings we need.\n"
      ],
      "id": "TF_wxIAhD07a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvYECABJJs_2"
      },
      "outputs": [],
      "source": [
        "client.indices.delete(index=\"elser-example-movies\", ignore_unavailable=True)\n",
        "client.indices.create(\n",
        "    index=\"elser-example-movies\",\n",
        "    settings={\"index\": {\"default_pipeline\": \"elser-ingest-pipeline\"}},\n",
        "    mappings={\n",
        "        \"properties\": {\n",
        "            \"plot\": {\n",
        "                \"type\": \"text\",\n",
        "                \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}},\n",
        "            },\n",
        "            \"plot_embedding\": {\"type\": \"sparse_vector\"},\n",
        "        }\n",
        "    },\n",
        ")"
      ],
      "id": "cvYECABJJs_2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFHgRUYVpNKP"
      },
      "source": [
        "## Insert Documents\n",
        "Let's insert our example dataset of 12 movies.\n",
        "\n",
        "If you get an error, check the model has been deployed and is available in the ML node. In newer versions of Elastic Cloud, ML node is autoscaled and the ML node may not be ready yet. Wait for a few minutes and try again."
      ],
      "id": "lFHgRUYVpNKP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBfqgdAcuKRG"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/notebooks/search/movies.json\"\n",
        "response = urlopen(url)\n",
        "\n",
        "# Load the response data into a JSON object\n",
        "data_json = json.loads(response.read())\n",
        "\n",
        "# Prepare the documents to be indexed\n",
        "documents = []\n",
        "for doc in data_json:\n",
        "    documents.append(\n",
        "        {\n",
        "            \"_index\": \"elser-example-movies\",\n",
        "            \"_source\": doc,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# Use helpers.bulk to index\n",
        "helpers.bulk(client, documents)\n",
        "\n",
        "print(\"Done indexing documents into `elser-example-movies` index!\")\n",
        "time.sleep(3)"
      ],
      "id": "IBfqgdAcuKRG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCj3jHHML4Tn"
      },
      "source": [
        "Inspect a new document to confirm that it now has an `plot_embedding` field that contains a list of new, additional terms.\n",
        "These terms are the **text expansion** of the field(s) you targeted for ELSER inference in `input_field` while creating the pipeline.\n",
        "ELSER essentially creates a tree of expanded terms to improve the semantic searchability of your documents.\n",
        "We'll be able to search these documents using a `text_expansion` query.\n",
        "\n",
        "But first let's start with a simple keyword search, to see how ELSER delivers semantically relevant results out of the box."
      ],
      "id": "oCj3jHHML4Tn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy5GT2xb38oz"
      },
      "source": [
        "# Searching Documents\n",
        "\n",
        "Let's test out semantic search using ELSER."
      ],
      "id": "Zy5GT2xb38oz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAZRxja-5Q6X"
      },
      "outputs": [],
      "source": [
        "response = client.search(\n",
        "    index=\"elser-example-movies\",\n",
        "    size=3,\n",
        "    query={\n",
        "        \"text_expansion\": {\n",
        "            \"plot_embedding\": {\n",
        "                \"model_id\": \".elser_model_2\",\n",
        "                \"model_text\": \"fighting movie\",\n",
        "            }\n",
        "        }\n",
        "    },\n",
        ")\n",
        "\n",
        "for hit in response[\"hits\"][\"hits\"]:\n",
        "    doc_id = hit[\"_id\"]\n",
        "    score = hit[\"_score\"]\n",
        "    title = hit[\"_source\"][\"title\"]\n",
        "    plot = hit[\"_source\"][\"plot\"]\n",
        "    print(f\"Score: {score}\\nTitle: {title}\\nPlot: {plot}\\n\")"
      ],
      "id": "bAZRxja-5Q6X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljkEzIQBBfF"
      },
      "source": [
        "## Next Steps\n",
        "Now that we have a working example of semantic search using ELSER, you can try it out on your own data. Don't forget to scale down the ML node when you are done."
      ],
      "id": "nljkEzIQBBfF"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}